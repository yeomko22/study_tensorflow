{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    plt.plot(time[start:end], series[start:end], format)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(True)\n",
    "\n",
    "def trend(time, slope=0):\n",
    "    return slope * time\n",
    "\n",
    "def seasonal_pattern(season_time):\n",
    "    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n",
    "    return np.where(season_time < 0.4,\n",
    "                    np.cos(season_time * 2 * np.pi),\n",
    "                    1 / np.exp(3 * season_time))\n",
    "\n",
    "def seasonality(time, period, amplitude=1, phase=0):\n",
    "    \"\"\"Repeats the same pattern at each period\"\"\"\n",
    "    season_time = ((time + phase) % period) / period\n",
    "    return amplitude * seasonal_pattern(season_time)\n",
    "\n",
    "def noise(time, noise_level=1, seed=None):\n",
    "    rnd = np.random.RandomState(seed)\n",
    "    return rnd.randn(len(time)) * noise_level\n",
    "\n",
    "time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
    "baseline = 10\n",
    "series = trend(time, 0.1)  \n",
    "baseline = 10\n",
    "amplitude = 40\n",
    "slope = 0.05\n",
    "noise_level = 5\n",
    "\n",
    "# Create the series\n",
    "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n",
    "# Update with noise\n",
    "series += noise(time, noise_level, seed=42)\n",
    "\n",
    "split_time = 1000\n",
    "time_train = time[:split_time]\n",
    "x_train = series[:split_time]\n",
    "time_valid = time[split_time:]\n",
    "x_valid = series[split_time:]\n",
    "\n",
    "window_size = 20\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(model, series, window_size):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
    "    ds = ds.batch(32).prefetch(1)\n",
    "    forecast = model.predict(ds)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 620ms/step - loss: 73.2800 - mae: 73.6896\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 72.6322 - mae: 72.9788\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 71.4605 - mae: 71.8377\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 70.0359 - mae: 70.4184\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 68.2689 - mae: 68.7583\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 66.4883 - mae: 66.8782\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 64.2616 - mae: 64.7354\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 62.0457 - mae: 62.3713\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 59.3746 - mae: 59.7458\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 56.3313 - mae: 56.8317\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 53.3244 - mae: 53.5844\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 49.4466 - mae: 49.9128\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 45.2945 - mae: 45.5964\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 41.5921 - mae: 41.9902\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 40.6574 - mae: 41.1555\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 39.5009 - mae: 40.0524\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 38.1321 - mae: 38.6531\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 36.6134 - mae: 37.1057\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 35.0407 - mae: 35.5333\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 33.6130 - mae: 34.0769\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 32.2603 - mae: 32.7742\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 31.0060 - mae: 31.5719\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 29.9019 - mae: 30.4469\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 28.9141 - mae: 29.3412\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 27.8442 - mae: 28.2367\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 26.6497 - mae: 27.1097\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 25.4563 - mae: 25.9551\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 24.2907 - mae: 24.7682\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 23.0599 - mae: 23.5445\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 21.6999 - mae: 22.2905\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 20.6535 - mae: 21.0224\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 19.3034 - mae: 19.7113\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 17.8995 - mae: 18.4525\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 16.9921 - mae: 17.4434\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 16.2409 - mae: 16.7384\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 15.6820 - mae: 16.1243\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 15.0608 - mae: 15.5439\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 14.4595 - mae: 15.0026\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 14.0791 - mae: 14.4808\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 13.4649 - mae: 13.9302\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 12.9145 - mae: 13.3710\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 12.3464 - mae: 12.7804\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 11.7356 - mae: 12.1553\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 11.0543 - mae: 11.5075\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 10.3970 - mae: 10.8390\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 9.6753 - mae: 10.1738\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 9.0906 - mae: 9.5766\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 8.6122 - mae: 9.0605\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 8.1542 - mae: 8.6017\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 7.7260 - mae: 8.1924\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 7.3652 - mae: 7.8068\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 6.9616 - mae: 7.4467\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 6.6863 - mae: 7.1167\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 6.3220 - mae: 6.7790\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 5.9906 - mae: 6.4550\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 5.7089 - mae: 6.1556\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 5.4460 - mae: 5.9035\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 5.2157 - mae: 5.6731\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 4.9922 - mae: 5.4522\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 4.8104 - mae: 5.3024\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 4.7175 - mae: 5.2023\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 4.9295 - mae: 5.3703\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 4.5738 - mae: 5.0650\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 4.7220 - mae: 5.1538\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 4.7053 - mae: 5.3071\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 5.2452 - mae: 5.8564\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 6.3944 - mae: 7.0185\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 5.8145 - mae: 6.2172\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 5.7929 - mae: 6.2083\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 6.1573 - mae: 6.6167\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 5.8503 - mae: 6.3295\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 6.4572 - mae: 7.0011\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 7.6252 - mae: 7.8872\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 15.5506 - mae: 15.6197\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 14.8549 - mae: 14.8218\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 15.6386 - mae: 15.4366\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 17.5484 - mae: 18.4639\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 17.5276 - mae: 18.2544\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 17.7635 - mae: 18.0921\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 9.7347 - mae: 10.0811\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 9.2012 - mae: 10.1283\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 9.4738 - mae: 9.6584\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 10.7859 - mae: 12.0523\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 25.7430 - mae: 26.5311\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 19.7741 - mae: 19.4900\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 11.0158 - mae: 11.8060\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 47ms/step - loss: 10.9255 - mae: 11.6367\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 11.3700 - mae: 12.0015\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 11.7735 - mae: 13.4100\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 28.7528 - mae: 29.0607\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 15.4962 - mae: 15.5951\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 22.9931 - mae: 22.6299\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 26.1823 - mae: 25.7465\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 17.5895 - mae: 17.6440\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 14.2346 - mae: 14.4800\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 20.0196 - mae: 20.1561\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 14.4974 - mae: 14.6962\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 19.3200 - mae: 19.7313\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 17.3532 - mae: 18.1741\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 18.6312 - mae: 19.4826\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(51)\n",
    "np.random.seed(51)\n",
    "\n",
    "window_size = 30\n",
    "train_set = windowed_dataset(x_train, window_size, batch_size=128, shuffle_buffer=shuffle_buffer_size)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n",
    "                      strides=1, padding=\"causal\",\n",
    "                      activation=\"relu\",\n",
    "                      input_shape=[None, 1]),\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
    "  tf.keras.layers.Dense(1),\n",
    "  tf.keras.layers.Lambda(lambda x: x * 200)\n",
    "])\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])\n",
    "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-08, 0.0001, 0, 30]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
    "plt.axis([1e-8, 1e-4, 0, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "31/31 [==============================] - 4s 116ms/step - loss: 21.5713 - mae: 22.3311\n",
      "Epoch 2/500\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 8.2302 - mae: 8.7146\n",
      "Epoch 3/500\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 6.6533 - mae: 7.1294\n",
      "Epoch 4/500\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 6.5045 - mae: 6.9897\n",
      "Epoch 5/500\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 5.9441 - mae: 6.4212\n",
      "Epoch 6/500\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 5.5678 - mae: 6.0458\n",
      "Epoch 7/500\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 5.3540 - mae: 5.8331\n",
      "Epoch 8/500\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 5.2692 - mae: 5.7491\n",
      "Epoch 9/500\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 5.2261 - mae: 5.6994\n",
      "Epoch 10/500\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 5.2973 - mae: 5.7732\n",
      "Epoch 11/500\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 5.1711 - mae: 5.6467\n",
      "Epoch 12/500\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 5.0422 - mae: 5.5175\n",
      "Epoch 13/500\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 5.0738 - mae: 5.5545\n",
      "Epoch 14/500\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 5.0245 - mae: 5.5123\n",
      "Epoch 15/500\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 5.0019 - mae: 5.4793\n",
      "Epoch 16/500\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 4.9367 - mae: 5.4086\n",
      "Epoch 17/500\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 4.9490 - mae: 5.4333\n",
      "Epoch 18/500\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 4.8578 - mae: 5.3355\n",
      "Epoch 19/500\n",
      "11/31 [=========>....................] - ETA: 0s - loss: 4.9129 - mae: 5.3906"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-62936d7f3ae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m               metrics=[\"mae\"])\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(51)\n",
    "np.random.seed(51)\n",
    "#batch_size = 16\n",
    "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv1D(filters=32, kernel_size=3,\n",
    "                      strides=1, padding=\"causal\",\n",
    "                      activation=\"relu\",\n",
    "                      input_shape=[None, 1]),\n",
    "  tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "  tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "  tf.keras.layers.Dense(1),\n",
    "  tf.keras.layers.Lambda(lambda x: x * 200)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])\n",
    "history = model.fit(dataset,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)\n",
    "rnn_forecast = rnn_forecast[split_time - window_size:-1, -1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plot_series(time_valid, x_valid)\n",
    "plot_series(time_valid, rnn_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "mae=history.history['mae']\n",
    "loss=history.history['loss']\n",
    "\n",
    "epochs=range(len(loss)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot MAE and Loss\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, mae, 'r')\n",
    "plt.plot(epochs, loss, 'b')\n",
    "plt.title('MAE and Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"MAE\", \"Loss\"])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "epochs_zoom = epochs[200:]\n",
    "mae_zoom = mae[200:]\n",
    "loss_zoom = loss[200:]\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot Zoomed MAE and Loss\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs_zoom, mae_zoom, 'r')\n",
    "plt.plot(epochs_zoom, loss_zoom, 'b')\n",
    "plt.title('MAE and Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"MAE\", \"Loss\"])\n",
    "\n",
    "plt.figure()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.0",
   "language": "python",
   "name": "tensorflow-2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
